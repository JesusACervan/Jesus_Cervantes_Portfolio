## Scrapes headers from websites to extract the different dishes in cuisines around the world.

import random as r
import re
import urllib.request
from urllib.request import Request, urlopen
from bs4 import BeautifulSoup


url="https://insanelygoodrecipes.com/cantonese-recipes/"
req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
html = urlopen(req).read()
webpage = html.decode('utf-8')
soup = BeautifulSoup(html, 'html.parser')
headerlist = soup.find_all(re.compile('^h[1-6]'))
can = []
for header in headerlist:
    can.append(header.text)
can = can[1:26]


url="https://www.chefspencil.com/30-popular-south-indian-foods-and-desserts/"
req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
html = urlopen(req).read()
webpage = html.decode('utf-8')
soup = BeautifulSoup(html, 'html.parser')
headerlist = soup.find_all(re.compile('^h[1-6]'))
sind = []
for header in headerlist:
    sind.append(header.text)
sind = sind[1:26]


url="https://thekitchencommunity.org/soul-food-recipes/"
req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
html = urlopen(req).read()
webpage = html.decode('utf-8')
soup = BeautifulSoup(html, 'html.parser')
headerlist = soup.find_all(re.compile('^h[1-6]'))
sou = []
for header in headerlist:
    sou.append(header.text)
sou = sou[1:26]


url="https://fullsuitcase.com/french-food/"
req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
html = urlopen(req).read()
webpage = html.decode('utf-8')
soup = BeautifulSoup(html, 'html.parser')
headerlist = soup.find_all(re.compile('^h[1-6]'))
fren = []
for header in headerlist:
    fren.append(header.text)
fren = fren[1:26]


url="https://www.byfood.com/blog/travel-tips/japanese-traditional-foods"
req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
html = urlopen(req).read()
webpage = html.decode('utf-8')
soup = BeautifulSoup(html, 'html.parser')
headerlist = soup.find_all(re.compile('^h[1-6]'))
jap = []
for header in headerlist:
    jap.append(header.text)
jap = jap[1:26]


url="https://foodandroad.com/thai-foods-traditional-dishes/"
req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
html = urlopen(req).read()
webpage = html.decode('utf-8')
soup = BeautifulSoup(html, 'html.parser')
headerlist = soup.find_all(re.compile('^h[1-6]'))
tha = []
for header in headerlist:
    tha.append(header.text)
tha = tha[1:26]

url="https://www.rainforestcruises.com/guides/india-food"
req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
html = urlopen(req).read()
webpage = html.decode('utf-8')
soup = BeautifulSoup(html, 'html.parser')
headerlist = soup.find_all(re.compile('^h[1-6]'))
ind = []
for header in headerlist:
    ind.append(header.text)
ind = ind[1:26]


url="https://www.purewow.com/food/traditional-chinese-food"
req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
html = urlopen(req).read()
webpage = html.decode('utf-8')
soup = BeautifulSoup(html, 'html.parser')
headerlist = soup.find_all(re.compile('^h[1-6]'))
chin = []
for header in headerlist:
    chin.append(header.text)
chin= chin[0:26]

## Converts the data extracted into a dataframe using pandas.
import pandas as pd

foodDict = {'Chinese': chin,
            'Indian':ind,
            'Thai':tha,
            'Japanese':jap,
            'French':fren,
            'Soul':sou,
            'South Indian':sind,
            'Cantonese':can}

Cuisine = pd.DataFrame.from_dict(foodDict)

## We want to extract the top 20 foods in the list and clean out anything that is not food related.

Cuisine.head()

chin = chin[4:24]
ind = ind[0:20]
tha = tha[1:21]
jap = jap[2:22]
fren = fren[0:20]
sou = sou[0:20]
sind = sind[3:23]
can = can[1:21]

foodDict = {'Chinese': chin,
            'Indian':ind,
            'Thai':tha,
            'Japanese':jap,
            'French':fren,
            'Soul':sou,
            'South Indian':sind,
            'Cantonese':can}

print(foodDict)

Cuisine = pd.DataFrame.from_dict(foodDict)
Cuisine.tail()

## Cleaning the data to only include the name of the cuisine
Cuisine['Chinese'] = Cuisine['Chinese'].str.strip('0123456789.')
Cuisine['Indian'] = Cuisine['Indian'].str.strip('0123456789.')
Cuisine['Thai'] = Cuisine['Thai'].str.strip('0123456789.')
Cuisine['Japanese'] = Cuisine['Japanese'].str.strip('0123456789.')
Cuisine['French'] = Cuisine['French'].str.strip('0123456789.')
Cuisine['Soul'] = Cuisine['Soul'].str.strip('0123456789.')
Cuisine['South Indian'] = Cuisine['South Indian'].str.strip('0123456789.')


## Creating the randomizer to suggest the cuisine and the specific dish to try
keys = Cuisine.keys()

while True:
    rand = r.randint(0, len(keys))
    if rand != len(keys):
        main = keys[rand]
        break;

elements = Cuisine[main]

while True:
    rand = r.randint(0, len(elements))
    if rand != len(elements):
        idea = elements[rand]
        break;

print('Today, you will eat ' + main + ' food, specifically' + idea + '. I hope you enjoy :)')
Cuisine['Cantonese'] = Cuisine['Cantonese'].str.strip('0123456789.')
